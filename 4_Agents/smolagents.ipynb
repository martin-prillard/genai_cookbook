{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4348e2e8",
   "metadata": {},
   "source": [
    "# Smolagents (Hugging Face)\n",
    "\n",
    "**Objectifs**  \n",
    "- D√©couvrir les **CodeAgent** et **ToolCallingAgent** avec **smolagents**.  \n",
    "- Utiliser un mod√®le **OpenAI** ou **Gemini** via `OpenAIServerModel` (vous avez `OPENAI_API_KEY` ou `GOOGLE_API_KEY`).  \n",
    "- Construire 2 outils : `calculator` (arithm√©tique) et `kb_lookup` (mini base locale).  \n",
    "- Comparer **CodeAgent** vs **ToolCallingAgent** sur 2‚Äì3 t√¢ches.\n",
    "\n",
    "> Docs utiles : guided tour, outils, mod√®les (OpenAI/Gemini).  \n",
    "> **Note** : D√©finissez `USE_GEMINI=1` dans votre `.env` pour utiliser Gemini au lieu d'OpenAI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f91442",
   "metadata": {},
   "source": [
    "## 0) Installation & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f259d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Try to load from .env file if available (optional)\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass  # dotenv not installed, that's okay\n",
    "\n",
    "# Determine which backend to use\n",
    "USE_GEMINI = os.environ.get(\"USE_GEMINI\", \"\").lower() in (\"1\", \"true\", \"yes\")\n",
    "\n",
    "if USE_GEMINI:\n",
    "    assert os.getenv(\"GOOGLE_API_KEY\"), \"‚ö†Ô∏è Please set GOOGLE_API_KEY in your environment!\"\n",
    "    print(\"‚úÖ OK: GOOGLE_API_KEY detected (Gemini mode)\")\n",
    "else:\n",
    "    assert os.getenv(\"OPENAI_API_KEY\"), \"‚ö†Ô∏è Please set OPENAI_API_KEY in your environment!\"\n",
    "    print(\"‚úÖ OK: OPENAI_API_KEY detected (OpenAI mode)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65743a17",
   "metadata": {},
   "source": [
    "## 1) Choisir le mod√®le (OpenAI ou Gemini)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5205c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import OpenAIServerModel\n",
    "\n",
    "# Determine which backend to use (from setup cell)\n",
    "USE_GEMINI = os.environ.get(\"USE_GEMINI\", \"\").lower() in (\"1\", \"true\", \"yes\")\n",
    "\n",
    "if USE_GEMINI:\n",
    "    # Use Gemini via OpenAI-compatible API\n",
    "    model = OpenAIServerModel(\n",
    "        model_id=\"gemini-2.0-flash-exp\",\n",
    "        api_base=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    "        api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    )\n",
    "    print(\"‚öôÔ∏è Using Gemini backend (gemini-2.0-flash-exp)\")\n",
    "else:\n",
    "    # Use OpenAI (default)\n",
    "    model = OpenAIServerModel(\n",
    "        model_id=\"gpt-4o-mini\",\n",
    "        api_base=\"https://api.openai.com/v1\",\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    )\n",
    "    print(\"‚öôÔ∏è Using OpenAI backend (gpt-4o-mini)\")\n",
    "\n",
    "print(model, dir(model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618ddba4",
   "metadata": {},
   "source": [
    "## 2) Cr√©er des outils (@tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c323114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import tool\n",
    "import re\n",
    "\n",
    "@tool\n",
    "def calculator(expr: str) -> str:\n",
    "    \"\"\"\n",
    "    √âvalue une expression arithm√©tique simple.\n",
    "\n",
    "    Args:\n",
    "        expr (str): Expression arithm√©tique √† √©valuer. Autoris√©s: chiffres, espaces, point d√©cimal,\n",
    "                    et op√©rateurs +, -, *, / ainsi que les parenth√®ses ( et ).\n",
    "    \"\"\"\n",
    "    if not re.fullmatch(r\"[0-9+\\-*/()\\s\\.]+\", expr):\n",
    "        return \"Expression non autoris√©e.\"\n",
    "    try:\n",
    "        return str(eval(expr, {\"__builtins__\": {}}, {}))\n",
    "    except Exception as e:\n",
    "        return f\"Erreur: {e}\"\n",
    "\n",
    "calculator(\"2+2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443edd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "KB = {\n",
    "  \"jbv\": \"Jambon-beurre Vegan\",\n",
    "  \"mtmgapd\": \"Mange ta main et garde l'autre pour demain\",\n",
    "}\n",
    "\n",
    "@tool\n",
    "def kb_lookup(term: str) -> str:\n",
    "    \"\"\"\n",
    "    Retourne une petite d√©finition depuis la KB locale (cl√© exacte).\n",
    "\n",
    "    Args:\n",
    "        term (str): cl√© exacte √† r√©cup√©rer dans la KB locale\n",
    "\n",
    "    Returns:\n",
    "        str: d√©finition associ√© au term\n",
    "    \"\"\"\n",
    "    return KB.get(term.lower(), f\"(inconnue) cl√©s={list(KB)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fe0d85",
   "metadata": {},
   "source": [
    "## 3) CodeAgent ‚Äî planifier et agir en √©crivant du *code*\n",
    "\n",
    "CodeAgent privil√©gie l‚Äôex√©cution directe du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a27e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent\n",
    "\n",
    "agent_code = CodeAgent(tools=[calculator, kb_lookup], model=model, add_base_tools=False)\n",
    "agent_code.run(\"Calcule 37*19, puis d√©finis 'mtmgapd' en une phrase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a33a72e",
   "metadata": {},
   "source": [
    "## 4) ToolCallingAgent ‚Äî *tool calls* JSON natifs du mod√®le\n",
    "\n",
    "ToolCallingAgent est un agent Tool-first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149af91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import ToolCallingAgent\n",
    "\n",
    "agent_tool = ToolCallingAgent(tools=[calculator, kb_lookup], model=model, add_base_tools=False)\n",
    "agent_tool.run(\"Calcule 37*19, puis d√©finis 'mtmgapd' en une phrase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752a3c09",
   "metadata": {},
   "source": [
    "## 5) Mini comparaison qualitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfab010",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "  \"Calcule 23*51 et donne une phrase d'explication.\",\n",
    "  \"Donne la d√©finition de 'mtmgapd' et un exemple tr√®s court.\",\n",
    "]\n",
    "for p in prompts:\n",
    "    print(\"\\n=== Prompt ===\", p)\n",
    "    print(\"\\n--- CodeAgent ---\")\n",
    "    print(agent_code.run(p))\n",
    "    print(\"\\n--- ToolCallingAgent ---\")\n",
    "    print(agent_tool.run(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582ef714",
   "metadata": {},
   "source": [
    "## 6) Questions\n",
    "1. Diff√©rence conceptuelle entre **CodeAgent** et **ToolCallingAgent** ?  \n",
    "2. Quand pr√©f√©reriez-vous l‚Äôun ou l‚Äôautre ? (indices : sandbox, latence, tra√ßabilit√©)  \n",
    "3. O√π placeriez-vous un **WebSearchTool** ou un **RAG** dans ce TP ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fa259a-2959-4afa-823e-d54cb523c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import Tool\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "class WebSearchTool(Tool):\n",
    "    name = \"web_search\"\n",
    "    description = \"Recherche web via DuckDuckGo (r√©sum√©s courts).\"\n",
    "\n",
    "    input_type = \"object\"\n",
    "    output_type = \"object\"\n",
    "\n",
    "    inputs = {\n",
    "        \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Requ√™te de recherche web\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    outputs = {\n",
    "        \"result\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"R√©sum√© des r√©sultats\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def forward(self, query: str):\n",
    "        with DDGS() as ddgs:\n",
    "            results = ddgs.text(query, max_results=5)\n",
    "\n",
    "        snippets = [r.get(\"body\", \"\") for r in results]\n",
    "        return {\"result\": \"\\n\".join(snippets[:3])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd36eb9e-4874-42f7-a670-bd5419a360b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, WebSearchTool, InferenceClientModel\n",
    "\n",
    "model = InferenceClientModel()\n",
    "agent = CodeAgent(tools=[WebSearchTool()], model=model, stream_outputs=True)\n",
    "\n",
    "agent.run(\"Fais une recherche web : Quel est l'√¢ge de Danny Seagren ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07150fb9-8c04-4762-93e5-4700f6c79b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent\n",
    "\n",
    "search_tool = WebSearchTool()\n",
    "\n",
    "agent = ToolCallingAgent(\n",
    "    tools=[search_tool],\n",
    "    model=model,\n",
    "    add_base_tools=False\n",
    ")\n",
    "\n",
    "agent.run(\"Fais une recherche web : Quel est l'√¢ge de Danny Seagren ?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0574afb",
   "metadata": {},
   "source": [
    "## üîé Bonus ‚Äî Sandbox & WebSearchTool (optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988e27e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indices:\n",
    "# - add_base_tools=True ajoute un interpr√©teur Python sandbox√© & web search (DuckDuckGo) selon l'env.\n",
    "# - Pour un vrai sandbox, voir la doc smolagents (E2B/Modal/Docker).\n",
    "from smolagents import CodeAgent\n",
    "agent_code2 = CodeAgent(tools=[kb_lookup], model=model, add_base_tools=True)\n",
    "agent_code2.run(\"Quel est le produit de 91*97 puis fais une recherche web sommaire sur 'RAG' ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af15ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from smolagents import ToolCollection, CodeAgent, InferenceClientModel\n",
    "from mcp import StdioServerParameters\n",
    "\n",
    "model = InferenceClientModel()\n",
    "\n",
    "server_parameters = StdioServerParameters(\n",
    "    command=\"uvx\",\n",
    "    args=[\"--quiet\", \"pubmedmcp@0.1.3\"],\n",
    "    env={\"UV_PYTHON\": \"3.12\", **os.environ},\n",
    ")\n",
    "\n",
    "with ToolCollection.from_mcp(server_parameters, trust_remote_code=True) as tool_collection:\n",
    "    agent = CodeAgent(tools=[*tool_collection.tools], add_base_tools=True, model=model)\n",
    "    agent.run(\"Please find a remedy for hangover.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd93a528-914a-4fa4-93a2-6f9f0211500e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
