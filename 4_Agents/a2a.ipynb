{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent2Agent (A2A) Protocol: Build Interoperable Agents\n",
    "\n",
    "In this notebook, you'll learn the Agent2Agent (A2A) protocol basics and build two simple interoperable agents that can exchange structured messages. We'll:\n",
    "\n",
    "- Understand the motivation behind A2A and a minimal message schema\n",
    "- Configure an OpenAI model and a base `Agent` that speaks A2A\n",
    "- Implement two example agents (Researcher and Writer) and a simple mediator\n",
    "- Run a multi-turn exchange end-to-end\n",
    "- Practice with an exercise and a bonus tool-use pattern\n",
    "\n",
    "Prerequisites: an environment variable `OPENAI_API_KEY` set with a valid key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OK: OPENAI_API_KEY detected\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Try to load from .env file if available (optional)\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass  # dotenv not installed, that's okay\n",
    "\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"⚠️ Please set OPENAI_API_KEY in your environment!\"\n",
    "print(\"✅ OK: OPENAI_API_KEY detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI client initialized.\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Literal, Optional, Dict, Any\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# quick sanity check (model listing might be blocked; instead do a no-op create)\n",
    "print(\"OpenAI client initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal A2A: Message Schema\n",
    "\n",
    "We'll use a compact message format inspired by A2A ideas:\n",
    "\n",
    "- `role`: \"system\" | \"user\" | \"assistant\" | \"tool\" | \"agent\"\n",
    "- `name`: optional identifier of the speaker agent\n",
    "- `content`: natural language content\n",
    "- `actions`: optional list of proposed actions (e.g., tool calls)\n",
    "- `metadata`: optional dict (e.g., routing hints)\n",
    "\n",
    "Agents exchange lists of these messages. A mediator (router) decides who speaks next.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class A2AMessage(BaseModel):\n",
    "    role: Literal[\"system\", \"user\", \"assistant\", \"tool\", \"agent\"]\n",
    "    content: str\n",
    "    name: Optional[str] = None\n",
    "    actions: Optional[List[Dict[str, Any]]] = None\n",
    "    metadata: Optional[Dict[str, Any]] = None\n",
    "\n",
    "class AgentConfig(BaseModel):\n",
    "    name: str\n",
    "    system_prompt: str = \"\"\n",
    "    model: str = \"gpt-4o-mini\"  # small, fast model suitable for classroom\n",
    "    temperature: float = 0.2\n",
    "\n",
    "class AgentResponse(BaseModel):\n",
    "    message: A2AMessage\n",
    "    stop: bool = False  # allow agent to signal completion\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, config: AgentConfig, client: OpenAI):\n",
    "        self.config = config\n",
    "        self.client = client\n",
    "\n",
    "    def build_prompt(self, history: List[A2AMessage]) -> List[Dict[str, str]]:\n",
    "        messages: List[Dict[str, str]] = []\n",
    "        if self.config.system_prompt:\n",
    "            messages.append({\"role\": \"system\", \"content\": self.config.system_prompt})\n",
    "        for m in history:\n",
    "            # map A2A roles to chat roles where reasonable\n",
    "            role = m.role if m.role in {\"system\", \"user\", \"assistant\"} else \"user\"\n",
    "            name = f\"{m.name}: \" if m.name else \"\"\n",
    "            content = name + m.content\n",
    "            messages.append({\"role\": role, \"content\": content})\n",
    "        return messages\n",
    "\n",
    "    def step(self, history: List[A2AMessage]) -> AgentResponse:\n",
    "        messages = self.build_prompt(history)\n",
    "        completion = self.client.chat.completions.create(\n",
    "            model=self.config.model,\n",
    "            temperature=self.config.temperature,\n",
    "            messages=[{\"role\": m[\"role\"], \"content\": m[\"content\"]} for m in messages],\n",
    "        )\n",
    "        content = completion.choices[0].message.content or \"\"\n",
    "        response = AgentResponse(\n",
    "            message=A2AMessage(role=\"agent\", name=self.config.name, content=content)\n",
    "        )\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two specialized agents that speak through the same A2A interface\n",
    "\n",
    "researcher = Agent(\n",
    "    AgentConfig(\n",
    "        name=\"Researcher\",\n",
    "        system_prompt=(\n",
    "            \"You are a helpful research assistant. \"\n",
    "            \"Summarize facts concisely, cite sources if possible. \"\n",
    "            \"When uncertain, ask clarifying questions.\"\n",
    "        ),\n",
    "    ),\n",
    "    client,\n",
    ")\n",
    "\n",
    "writer = Agent(\n",
    "    AgentConfig(\n",
    "        name=\"Writer\",\n",
    "        system_prompt=(\n",
    "            \"You are a clear technical writer. \"\n",
    "            \"Transform research notes into a polished, short paragraph.\"\n",
    "        ),\n",
    "    ),\n",
    "    client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Researcher:\n",
      "Agent2Agent (A2A) refers to a communication framework or protocol that enables different agents (which could be software agents, AI systems, or robotic entities) to interact and collaborate with each other. A2A facilitates the exchange of information, coordination of tasks, and sharing of resources among agents, allowing them to work together more effectively to achieve common goals. This concept is often applied in fields such as multi-agent systems, distributed artificial intelligence, and robotics.\n",
      "\n",
      "If you need more specific details or applications of A2A, please let me know!\n",
      "\n",
      "\n",
      "Writer:\n",
      "Agent2Agent (A2A) is a communication framework that enables various agents—such as software programs, AI systems, or robotic entities—to interact and collaborate effectively. By facilitating the exchange of information, task coordination, and resource sharing, A2A allows these agents to work together towards common objectives. This concept is particularly relevant in areas like multi-agent systems, distributed artificial intelligence, and robotics.\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Route:\n",
    "    # Simple routing rule: after 'Researcher' speaks, 'Writer' responds; then stop\n",
    "    next_map: Dict[str, Optional[str]]\n",
    "\n",
    "    def next_speaker(self, current_name: str) -> Optional[str]:\n",
    "        return self.next_map.get(current_name)\n",
    "\n",
    "route = Route(next_map={\n",
    "    \"Researcher\": \"Writer\",\n",
    "    \"Writer\": None,  # stop after writer responds\n",
    "})\n",
    "\n",
    "history: List[A2AMessage] = [\n",
    "    A2AMessage(role=\"user\", name=\"Instructor\", content=\"Explain what Agent2Agent (A2A) is, briefly.\"),\n",
    "]\n",
    "\n",
    "# First, the Researcher responds\n",
    "resp_r = researcher.step(history)\n",
    "history.append(resp_r.message)\n",
    "print(f\"{resp_r.message.name}:\\n{resp_r.message.content}\\n\\n\")\n",
    "\n",
    "# Then route to Writer, who polishes the response\n",
    "next_name = route.next_speaker(\"Researcher\")\n",
    "if next_name == \"Writer\":\n",
    "    resp_w = writer.step(history)\n",
    "    history.append(resp_w.message)\n",
    "    print(f\"{resp_w.message.name}:\\n{resp_w.message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Add a Fact-Checker Agent\n",
    "\n",
    "- Create a third agent `FactChecker` whose role is to critique the Researcher output and ask for clarifications if needed.\n",
    "- Update the routing so that the turn order is: Researcher -> FactChecker -> Writer.\n",
    "- Keep the same `A2AMessage` history so all agents see the conversation context.\n",
    "\n",
    "Hint: copy the `Agent` instantiation pattern used for `researcher` and `writer` with a system prompt like: \"You verify factual claims, request sources, and highlight ambiguities.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Simple Tool-Use via A2A Actions\n",
    "\n",
    "We can simulate tool-use by allowing an agent to propose an action in `actions`, and a separate tool-runner to execute it. Below is a toy calculator tool the Researcher can call.\n",
    "\n",
    "Run once to define tool and an agent that may propose actions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "TOOLS: Dict[str, Callable[..., Any]] = {}\n",
    "\n",
    "def tool(name: str):\n",
    "    def decorator(fn: Callable[..., Any]):\n",
    "        TOOLS[name] = fn\n",
    "        return fn\n",
    "    return decorator\n",
    "\n",
    "@tool(\"calculator\")\n",
    "def calculator(expr: str) -> str:\n",
    "    try:\n",
    "        # Danger: eval — keep to math-only by removing builtins\n",
    "        result = eval(expr, {\"__builtins__\": {}}, {\"sqrt\": sqrt})\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"ERROR: {e}\"\n",
    "\n",
    "class ToolAwareAgent(Agent):\n",
    "    def step(self, history: List[A2AMessage]) -> AgentResponse:\n",
    "        # Let the LLM propose an action via a protocol hint\n",
    "        prompt_hint = (\n",
    "            \"If you need to compute something, propose an action in JSON as: \"\n",
    "            \"ACTION: {\\\"tool\\\": \\\"calculator\\\", \\\"input\\\": \\\"...\\\"}. \"\n",
    "            \"Otherwise, answer normally.\"\n",
    "        )\n",
    "        extended = history + [A2AMessage(role=\"system\", content=prompt_hint)]\n",
    "        resp = super().step(extended)\n",
    "\n",
    "        # crude parse for ACTION: {...}\n",
    "        import re, json\n",
    "        match = re.search(r\"ACTION:\\s*(\\{.*\\})\", resp.message.content, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                action = json.loads(match.group(1))\n",
    "                tool_name = action.get(\"tool\")\n",
    "                tool_input = action.get(\"input\", \"\")\n",
    "                if tool_name in TOOLS:\n",
    "                    tool_result = TOOLS[tool_name](tool_input)\n",
    "                    tool_msg = A2AMessage(role=\"tool\", name=tool_name, content=str(tool_result))\n",
    "                    # Have the agent incorporate the tool result\n",
    "                    follow_up = super().step(history + [resp.message, tool_msg])\n",
    "                    return follow_up\n",
    "            except Exception:\n",
    "                pass\n",
    "        return resp\n",
    "\n",
    "calc_researcher = ToolAwareAgent(\n",
    "    AgentConfig(\n",
    "        name=\"Researcher\",\n",
    "        system_prompt=(\n",
    "            \"You are a research assistant who can optionally use a calculator tool. \"\n",
    "            \"When asked to compute, propose an ACTION with a simple expression e.g. '2+2' or 'sqrt(9)'.\"\n",
    "        ),\n",
    "    ),\n",
    "    client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Researcher:\n",
      "To solve the expression \\( \\sqrt{144} + 10 \\), we first need to calculate \\( \\sqrt{144} \\).\n",
      "\n",
      "The square root of 144 is 12, since \\( 12 \\times 12 = 144 \\).\n",
      "\n",
      "Now, we add 10 to this result:\n",
      "\n",
      "\\( 12 + 10 = 22 \\).\n",
      "\n",
      "Thus, the final answer is 22.\n"
     ]
    }
   ],
   "source": [
    "# Ask the tool-aware researcher a question that requires computation\n",
    "history_calc: List[A2AMessage] = [\n",
    "    A2AMessage(role=\"user\", name=\"Instructor\", content=\"What is sqrt(144) + 10? Answer with reasoning and final number.\"),\n",
    "]\n",
    "resp_calc = calc_researcher.step(history_calc)\n",
    "print(f\"{resp_calc.message.name}:\\n{resp_calc.message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Researcher:\n",
      "Agent2Agent (A2A) refers to a communication framework or protocol that enables different autonomous agents to interact and collaborate with each other. This can involve sharing information, negotiating, or coordinating actions to achieve common goals. A2A systems are often used in fields like artificial intelligence, robotics, and distributed computing, where multiple agents need to work together effectively. The specifics of A2A can vary depending on the context and application, such as in multi-agent systems or decentralized networks. \n",
      "\n",
      "If you need more detailed information or specific applications of A2A, please let me know!\n",
      "\n",
      "\n",
      "FactChecker:\n",
      "Your explanation of Agent2Agent (A2A) is generally accurate, highlighting its role in enabling communication and collaboration among autonomous agents. However, it would be beneficial to clarify that A2A can encompass various protocols and standards, such as FIPA (Foundation for Intelligent Physical Agents) or other frameworks tailored for specific applications. Additionally, providing examples of real-world applications or specific fields where A2A is implemented could enhance the explanation. \n",
      "\n",
      "If you have specific sources or references to support your claims, including those would strengthen your response.\n",
      "\n",
      "\n",
      "Writer:\n",
      "Agent2Agent (A2A) is a communication framework that facilitates interaction and collaboration among autonomous agents, allowing them to share information, negotiate, and coordinate actions to achieve shared objectives. This framework is applicable in various domains, including artificial intelligence, robotics, and distributed computing, where effective cooperation among multiple agents is essential. A2A can incorporate various protocols and standards, such as the Foundation for Intelligent Physical Agents (FIPA), tailored to specific applications. Real-world implementations of A2A can be found in multi-agent systems for automated trading, smart grid management, and collaborative robotics, demonstrating its versatility and importance in enhancing agent interactions.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate FactChecker and run Researcher -> FactChecker -> Writer\n",
    "fact_checker = Agent(\n",
    "    AgentConfig(\n",
    "        name=\"FactChecker\",\n",
    "        system_prompt=(\n",
    "            \"You verify factual claims, request sources, and highlight ambiguities. \"\n",
    "            \"Be concise and constructive; suggest corrections or needed citations.\"\n",
    "        ),\n",
    "    ),\n",
    "    client,\n",
    ")\n",
    "\n",
    "# New route order\n",
    "route_fc = {\n",
    "    \"Researcher\": \"FactChecker\",\n",
    "    \"FactChecker\": \"Writer\",\n",
    "    \"Writer\": None,\n",
    "}\n",
    "\n",
    "def run_with_fact_checker(user_prompt: str) -> None:\n",
    "    convo: List[A2AMessage] = [\n",
    "        A2AMessage(role=\"user\", name=\"Instructor\", content=user_prompt)\n",
    "    ]\n",
    "\n",
    "    # Researcher turn\n",
    "    resp_r = researcher.step(convo)\n",
    "    convo.append(resp_r.message)\n",
    "    print(f\"{resp_r.message.name}:\\n{resp_r.message.content}\\n\\n\")\n",
    "\n",
    "    # FactChecker turn\n",
    "    if route_fc[\"Researcher\"] == \"FactChecker\":\n",
    "        resp_f = fact_checker.step(convo)\n",
    "        convo.append(resp_f.message)\n",
    "        print(f\"{resp_f.message.name}:\\n{resp_f.message.content}\\n\\n\")\n",
    "\n",
    "    # Writer turn\n",
    "    if route_fc[\"FactChecker\"] == \"Writer\":\n",
    "        resp_w = writer.step(convo)\n",
    "        convo.append(resp_w.message)\n",
    "        print(f\"{resp_w.message.name}:\\n{resp_w.message.content}\")\n",
    "\n",
    "# Example run\n",
    "run_with_fact_checker(\"Explain what Agent2Agent (A2A) is, briefly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
